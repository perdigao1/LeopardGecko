{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enhanced-cartoon",
   "metadata": {},
   "source": [
    "# Leopardgecko - AvgPooling3DConsistencyData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-freight",
   "metadata": {},
   "source": [
    "## Average pooling of h5 volumetric data that was 'predicted' and combined using the neural network predictor\n",
    "  \n",
    "Divide volume in 512x512x512 volumes to be processed with PyTorch's AvgPool3D.\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool3d.html\n",
    "\n",
    "(Arrays may need to be converted from hdf5 to numpy before passing to pytorch.)  \n",
    "\n",
    "Stores resulting averaging in another (smaller) array. Also keep track of the X,Y,Z coordinate indexes on the original data corresponding to each element in this average volume calculation.\n",
    "\n",
    "Data is saved in a hdf5 with filename added suffix \"\\_VolAvg_k\\<k_width\\>\\_s\\<s_stride\\>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "voluntary-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import dask.array as da\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "#For showing nested loop progress in notebook\n",
    "from IPython.display import clear_output\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frank-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch helping functions to do the Average pooling using GPU if possible\n",
    "def AvgPool3DPytorchGPU(data3d_np , kwidth=8 , stride0=1):\n",
    "\n",
    "    assert torch.cuda.is_available(), \"CUDA not available, terminating...\"\n",
    "    \n",
    "    #convert to torch objects, and to gpu using cuda()\n",
    "    data3d_torch = torch.unsqueeze( torch.unsqueeze( torch.from_numpy(data3d_np),0),0 ).cuda()\n",
    "    \n",
    "    #setup torch calculation\n",
    "    torchc3d = torch.nn.AvgPool3d(kwidth, stride0)\n",
    "    \n",
    "    result = torchc3d(data3d_torch)\n",
    "    \n",
    "    return result.cpu().detach().numpy()[0][0]\n",
    "\n",
    "def AvgPool3DPytorch(data3d_np , kwidth=8 , stride0=1):\n",
    "    #Generic. It will use the GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "            dev=\"cuda:0\"\n",
    "    else:\n",
    "            dev=\"cpu\"\n",
    "    device = torch.device(dev)\n",
    "    \n",
    "    #convert to torch objects, and to gpu using cuda()\n",
    "    data3d_torch = torch.unsqueeze( torch.unsqueeze( torch.from_numpy(data3d_np),0),0 ).to(device)\n",
    "    \n",
    "    #setup torch calculation\n",
    "    torchc3d = torch.nn.AvgPool3d(kwidth, stride0)\n",
    "    \n",
    "    #Run the calculation\n",
    "    result = torchc3d(data3d_torch)\n",
    "    \n",
    "    return result.cpu().detach().numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opposite-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_halfwayZslice(data3d):\n",
    "    plt.imshow( data3d[ int(data3d.shape[0]/2), :, : ] )\n",
    "    print(\"shape:\" , data3d.shape, \"slice:\", int(data3d.shape[0]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aboriginal-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConsistencyWeightData_AutoMaxMin(largedata_da):\n",
    "    print(\"Determining vmax and vmin\")\n",
    "    #Created weighted data, weighting it with a square function\n",
    "    vmax = da.max(datahdf5_as_daskArray).compute()\n",
    "    vmin = da.min(datahdf5_as_daskArray).compute()\n",
    "    print(\"vmax: \" , vmax , \"  vmin: \" , vmin)\n",
    "    vaverage = 0.5*(vmax-vmin)\n",
    "    data_da_weighted = da.square(datahdf5_as_daskArray - vaverage) #weighting values\n",
    "    print (\"data_da_weighted.shape = \", data_da_weighted.shape)\n",
    "    return data_da_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "higher-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetVolAverageCornerAt(data_da_weighted, iz,iy,ix , w_avg , k_width, s_stride ):\n",
    "    #Check all is ok\n",
    "    assert ( iz >=0 and iy>=0 and ix>=0 ) , \"Error, indexes cannot be < 0 .\"\n",
    "    \n",
    "    assert ( iz < data_da_weighted.shape[0] and\n",
    "            iy < data_da_weighted.shape[1] and\n",
    "            ix < data_da_weighted.shape[2]) , \"Error, invlaid indexes.\"\n",
    "    \n",
    "    #Adjust limits\n",
    "    iz_da_min = iz\n",
    "    iz_da_max = iz_da_min + w_avg\n",
    "    if iz_da_max > data_da_weighted.shape[0] :\n",
    "        iz_da_max = data_da_weighted.shape[0]\n",
    "        iz_da_min = iz_da_max- w_avg\n",
    "    \n",
    "    iy_da_min = iy\n",
    "    iy_da_max = iy_da_min + w_avg\n",
    "    if iy_da_max > data_da_weighted.shape[1] :\n",
    "        iy_da_max = data_da_weighted.shape[1]\n",
    "        iy_da_min = iy_da_max- w_avg\n",
    "    \n",
    "    ix_da_min = ix\n",
    "    ix_da_max = ix_da_min + w_avg\n",
    "    if ix_da_max > data_da_weighted.shape[2] :\n",
    "        ix_da_max = data_da_weighted.shape[2]\n",
    "        ix_da_min = ix_da_max- w_avg\n",
    "    \n",
    "    print( \"iz_da_min=\", iz_da_min,\", iz_da_max=\", iz_da_max,\n",
    "          \", iy_da_min=\", iy_da_min,\", iy_da_max=\", iy_da_max,\n",
    "          \", ix_da_min=\", ix_da_min,\", ix_da_max=\", ix_da_max\n",
    "         )\n",
    "    \n",
    "    #Get volume and convert to numpy array\n",
    "    datavol_da = data_da_weighted [ iz_da_min:iz_da_max , iy_da_min:iy_da_max , ix_da_min:ix_da_max ]\n",
    "\n",
    "    #print(\"datavol_da.shape = \", datavol_da.shape)\n",
    "    #convert to numpy\n",
    "    datavol_np = datavol_da.compute()\n",
    "    #print(\"datavol_np.shape = \", datavol_np.shape)\n",
    "\n",
    "    #Calculate here the AvgPooling (big calculation)\n",
    "    datavol_avg = AvgPool3DPytorchGPU(datavol_np , k_width , s_stride )\n",
    "\n",
    "    print (\"AvgPool3D calculation complete\")\n",
    "    print(\"datavol_avg.shape = \",datavol_avg.shape)\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return datavol_avg, (iz_da_min , iz_da_max , iy_da_min , iy_da_max , ix_da_min , ix_da_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "democratic-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AvgPool3D_LargeData(largedata_da , w_avg = 512, k_width=256 , s_stride=8 , do_weighting = True):\n",
    "    #This function will do the avarage pooling in 3D using PyTorch AvgPool3D\n",
    "    #It splits data into chunks automatically\n",
    "    #and then combines the data automaticaly\n",
    "    #It returns the average for each point.\n",
    "    \n",
    "    assert (w_avg > k_width), \"w_avg (window width average) should be higher than kwidth\"\n",
    "    \n",
    "    if (do_weighting):\n",
    "        data_da_weighted = ConsistencyWeightData_AutoMaxMin(largedata_da)\n",
    "    else:\n",
    "        data_da_weighted = largedata_da\n",
    "    \n",
    "    \n",
    "    result_avg_of_vols = np.zeros( ( int( (data_da_weighted.shape[0]-k_width)/s_stride )+1 , \n",
    "                           int( (data_da_weighted.shape[1]-k_width)/s_stride )+1  ,\n",
    "                           int( (data_da_weighted.shape[2]-k_width)/s_stride )+1  ))\n",
    "\n",
    "    print (\"result_avg_of_vols.shape = \" , result_avg_of_vols.shape)\n",
    "    \n",
    "    # BIG CALCULATION\n",
    "    \n",
    "    #Nested iterations of w_avg x w_avg x w_avg volumes\n",
    "    #step0 = int( (w_avg - k_width) / s_stride )\n",
    "    step0 = int(w_avg - k_width)\n",
    "    \n",
    "    niter = 0 #Count the number of ierations\n",
    "    time0 = time.perf_counter()\n",
    "    time1 = time0\n",
    "    \n",
    "    ntotaliter = int(data_da_weighted.shape[0]/step0) * int(data_da_weighted.shape[1]/step0)* int(data_da_weighted.shape[2]/step0)\n",
    "    \n",
    "    print (\"ntotaliter  = \", ntotaliter)\n",
    "    \n",
    "    time.sleep(2) #A little pause to see print output\n",
    "    \n",
    "    for iz_da in range(0 , data_da_weighted.shape[0] , step0):\n",
    "        for iy_da in range(0 , data_da_weighted.shape[1] , step0):\n",
    "            for ix_da in range(0 , data_da_weighted.shape[2] , step0):\n",
    "            \n",
    "                #Show progress\n",
    "                #clear_output(wait=True)\n",
    "                \n",
    "                if (niter>0):\n",
    "                    print(\"niteration = \", niter , \"/\", ntotaliter)\n",
    "                    print (\"Estimated time to finish (s) = \",\n",
    "                           str( round( (ntotaliter-niter)*(time1-time0)/niter) ) )\n",
    "                \n",
    "                print(\"iz_da=\", iz_da , \"/\" , data_da_weighted.shape[0] ,\n",
    "                      \" , iy_da=\", iy_da , \"/\" , data_da_weighted.shape[1] ,\n",
    "                      \" , ix_da=\", ix_da , \"/\" , data_da_weighted.shape[2]\n",
    "                     )\n",
    "\n",
    "                datavol_avg , index_limits = GetVolAverageCornerAt(data_da_weighted, iz_da,iy_da,ix_da , w_avg , k_width, s_stride )\n",
    "                \n",
    "                clear_output(wait=True)\n",
    "                \n",
    "                time1 = time.perf_counter()\n",
    "                niter += 1\n",
    "                \n",
    "                #With data collected, store it in appropriate array \n",
    "                print(\"index_limits = \", index_limits)\n",
    "                iz = int(index_limits[0] / s_stride)\n",
    "                iy = int(index_limits[2] / s_stride)\n",
    "                ix = int(index_limits[4] / s_stride)\n",
    "\n",
    "                print (\"Start indexes to store at result_avg_of_vols: \" , iz , iy , ix)\n",
    "\n",
    "                result_avg_of_vols[ iz : (iz + datavol_avg.shape[0]) ,\n",
    "                                  iy : (iy + datavol_avg.shape[1]) ,\n",
    "                                  ix : (ix + datavol_avg.shape[2]) ] = datavol_avg\n",
    "\n",
    "    print(\"Completed.\")      \n",
    "    \n",
    "    \n",
    "    #Create the respective indexes\n",
    "    #Indexes are the midpoints of the respective averaging volume\n",
    "    # (No index should have a value of 0)\n",
    "    result_avg_of_vols_x_range = np.arange( int(k_width/2) , data_da_weighted.shape[2]-int(k_width/2)+1, s_stride )\n",
    "    result_avg_of_vols_y_range = np.arange( int(k_width/2) , data_da_weighted.shape[1]-int(k_width/2)+1 , s_stride )\n",
    "    result_avg_of_vols_z_range = np.arange( int(k_width/2) , data_da_weighted.shape[0]-int(k_width/2)+1 , s_stride )\n",
    "\n",
    "    #Attention, order of x,y,z has to be in this way\n",
    "    #otherwise the vales will not correspond to the averaging point volumes.\n",
    "    #In a 3D array, first index is zz, 2nd is yy, and 3rd is xx\n",
    "    result_avg_of_vols_z , result_avg_of_vols_y , result_avg_of_vols_x = np.meshgrid( result_avg_of_vols_z_range ,\n",
    "                                                                                    result_avg_of_vols_y_range,\n",
    "                                                                                    result_avg_of_vols_x_range,\n",
    "                                                                                    indexing='ij')\n",
    "    #Resulting meshgrids should have the same shape as result_avg_of_vols\n",
    "    print (\"result_avg_of_vols_x.shape = \", result_avg_of_vols_x.shape )\n",
    "    \n",
    "    #TODO Return the averaged data and the X , Y and Z indices\n",
    "    return result_avg_of_vols , result_avg_of_vols_z , result_avg_of_vols_y , result_avg_of_vols_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sized-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input filename\n",
    "# Change as appropriate\n",
    "# The location of the file is for LMAP VM in Guacamole\n",
    "data_filename = '/workspace/for_luis/2020-05-15_final_4_volumes_combined.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "failing-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opens file\n",
    "fx= h5py.File(data_filename,'r')\n",
    "datahdf5_as_daskArray = da.from_array(fx['data'], chunks='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-isolation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_limits =  (1024, 1536, 2008, 2520, 1024, 1536)\n",
      "Start indexes to store at result_avg_of_vols:  8 15 8\n",
      "niteration =  485 / 648\n",
      "Estimated time to finish (s) =  653\n",
      "iz_da= 1024 / 2120  , iy_da= 2048 / 2520  , ix_da= 1280 / 2520\n",
      "iz_da_min= 1024 , iz_da_max= 1536 , iy_da_min= 2008 , iy_da_max= 2520 , ix_da_min= 1280 , ix_da_max= 1792\n"
     ]
    }
   ],
   "source": [
    "#Do the averaging (long)\n",
    "#For testing, change stride to higher values, such as 32 or 64\n",
    "w_avg = 512\n",
    "k_width = 256\n",
    "s_stride= 128\n",
    "result_avg_of_vols_tuple = AvgPool3D_LargeData(datahdf5_as_daskArray , w_avg, k_width , s_stride, do_weighting = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpack result\n",
    "(result_avg_of_vols , result_avg_of_vols_z , result_avg_of_vols_y, result_avg_of_vols_x) = result_avg_of_vols_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check of result\n",
    "show_halfwayZslice(result_avg_of_vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "still-marketplace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "#os.path.split('/workspace/for_luis/2020-04-09_final_4_volumes_combined.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "american-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "#os.path.splitext('2020-04-09_final_4_volumes_combined.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "realistic-flesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15_final_4_volumes_combined_VolAvg_k256_s128.h5\n"
     ]
    }
   ],
   "source": [
    "#Save file (locally, at the same folder as this notebook)\n",
    "pathhead, pathtail = os.path.split(data_filename)\n",
    "pathname , ext = os.path.splitext(pathtail)\n",
    "newpathname = pathname + \"_VolAvg_k\" + str(k_width)+\"_s\"+str(s_stride)\n",
    "newfilename = newpathname + '.h5'\n",
    "print (newfilename)\n",
    "\n",
    "with h5py.File(newfilename ,'w') as f:\n",
    "    f['/data']= result_avg_of_vols\n",
    "    f['/Z']= result_avg_of_vols_z\n",
    "    f['/Y']= result_avg_of_vols_y\n",
    "    f['/X']= result_avg_of_vols_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
